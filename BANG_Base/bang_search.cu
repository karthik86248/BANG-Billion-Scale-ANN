/* Copyright 2024 Indian Institute Of Technology Hyderbad, India. All Rights Reserved.
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
    http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/
// Authors: Karthik V., Saim Khan, Somesh Singh
//

// bang headers
#include "bang_search.cuh"
#include "utils/utils.h"
#include "utils/timer.h"

// System headers
#include <assert.h>
#include <omp.h>
#include <sys/mman.h>

// CUDA
#include <cub/cub.cuh>

// STL
#include <iostream>
#include <cstdio>
#include <fstream>
#include <cstdint>
#include <vector>

#define MAX_R 64 // Max. node degree supported

// File name suffixes of various o/p files generated by DiskANN Graph construction (Vamana)
#define PQ_PIVOTS_FILE_SUFFIX "_pq_pivots.bin"
#define PQ_COMPRESSEDVECTORS_FILE_SUFFIX "_pq_compressed.bin"
//#define PQ_CHUNK_OFFSETS_FILE_SUFFIX "_pq_pivots.bin_chunk_offsets.bin"
//#define PQ_CENTROID_FILE_SUFFIX "_pq_pivots.bin_centroid.bin"
#define PQ_PIVOTS_NUM_SECTIONS (3)
#define GRAPH_INDEX_FILE_SUFFIX "_disk.bin"
#define GRAPH_INDEX_METADATA_FILE_SUFFIX "_disk_metadata.bin" // This is explicitly generated by running BANG script bang_preprocess.py

// The size of Bloom Filter.
#define BF_ENTRIES  399887U // BF is maintained per query (prime number close to 4k)
						   // For lower recall values, possible values used:  10007 (skip), 4999, 3001, (1999 skip), 1501, 999 (skip), 299 (skip)
const unsigned BF_MEMORY = (BF_ENTRIES & 0xFFFFFFFC) + sizeof(unsigned); // 4-byte mem aligned size for actual allocation

// Indicates static upper bound on search iterations performed
#define NAX_EXTRA_ITERATION		(50)
#define MAX_PARENTS_PERQUERY  (MAX_L + NAX_EXTRA_ITERATION) //Needs to be set with expereince. set it to (2*MAX_L), if in doubt

// Per query, nly one Candidate (Parent) is send from GPU to CPU  to fetch its neighbours from the Graph Index.
// In future, we could use multiple Parents.
#define SIZEPARENTLIST  (1+1) // one to indicate present/absent and other the actual parent ID

//#define _TIMERS
//#define _DBG_CAND
//#define _NO_PRETECH
//#define _NO_ASYNC_FP

//#define _DBG_BOUNDS

using namespace std;
using Clock = std::chrono::high_resolution_clock;

template <typename T>
BANGSearch<T>::BANGSearch()
{
	m_pImpl = new BANGSearchInner<int>();
}

template<typename T>
BANGSearch<T>::~BANGSearch()
{
	BANGSearchInner<T>* pobjBangInner = static_cast<BANGSearchInner<T>*>(m_pImpl);
	delete pobjBangInner;
}

template<typename T>
bool BANGSearch<T>::bang_load( char* indexfile_path_prefix)
{
	BANGSearchInner<T>* pobjBangInner = static_cast<BANGSearchInner<T>*>(m_pImpl);
	return pobjBangInner->bang_load(indexfile_path_prefix);
}

template<typename T>
void BANGSearch<T>::bang_alloc(int numQueries)
{
	BANGSearchInner<T>* pobjBangInner = static_cast<BANGSearchInner<T>*>(m_pImpl);
	pobjBangInner->bang_alloc(numQueries);
}

template<typename T>
void BANGSearch<T>::bang_init(int numQueries)
{
	BANGSearchInner<T>* pobjBangInner = static_cast<BANGSearchInner<T>*>(m_pImpl);
	pobjBangInner->bang_init(numQueries);
}

template<typename T>
void BANGSearch<T>::bang_set_searchparams(int recall,
                            int worklist_length,
                            DistFunc nDistFunc)
{
	BANGSearchInner<T>* pobjBangInner = static_cast<BANGSearchInner<T>*>(m_pImpl);
	return pobjBangInner->bang_set_searchparams(recall, worklist_length, nDistFunc);
}

template<typename T>
void BANGSearch<T>::bang_query(T* query_array,
                    int num_queries,
                    result_ann_t* nearestNeighbours,
					float* nearestNeighbours_dist )
{
	BANGSearchInner<T>* pobjBangInner = static_cast<BANGSearchInner<T>*>(m_pImpl);
	pobjBangInner->bang_query(query_array, num_queries, nearestNeighbours, nearestNeighbours_dist);
}

template<typename T>
void BANGSearch<T>::bang_free()
{
	BANGSearchInner<T>* pobjBangInner = static_cast<BANGSearchInner<T>*>(m_pImpl);
	pobjBangInner->bang_free();
}

template<typename T>
void BANGSearch<T>::bang_unload()
{
	BANGSearchInner<T>* pobjBangInner = static_cast<BANGSearchInner<T>*>(m_pImpl);
	pobjBangInner->bang_unload();
}


template<typename T>
bool BANGSearchInner<T>::bang_load(char* indexfile_path_prefix)
{
	string diskann_Generatedfiles_path = string(indexfile_path_prefix);
	string pqPivots_file = diskann_Generatedfiles_path +  PQ_PIVOTS_FILE_SUFFIX;//string(argv[1]); // Pivot files
	string compressedVector_file = diskann_Generatedfiles_path + PQ_COMPRESSEDVECTORS_FILE_SUFFIX;//string(argv[2]);
	string graphAdjListAndFP_file = diskann_Generatedfiles_path + GRAPH_INDEX_FILE_SUFFIX;//string(argv[3]);
	string graphMetadata_file = diskann_Generatedfiles_path + GRAPH_INDEX_METADATA_FILE_SUFFIX;//string(argv[3]);
    //string chunkOffsets_file = diskann_Generatedfiles_path + PQ_CHUNK_OFFSETS_FILE_SUFFIX ;//string(argv[5]);
	//string centroid_file = diskann_Generatedfiles_path + PQ_CENTROID_FILE_SUFFIX;////string(argv[2]);
	bool bRet = true;

	
	// Check if files exist
	ifstream in1(pqPivots_file, std::ios::binary);
	if(!in1.is_open()){
		printf("Error.. Could not open the PQ Pivots File: %s", pqPivots_file.c_str() );
		return false;
	}

	ifstream in2(compressedVector_file, std::ios::binary);
	if(!in2.is_open()){
		printf("Error.. Could not open the PQ Compressed Vectors File: %s", compressedVector_file.c_str() );
		return false;
	}


	ifstream in3(graphAdjListAndFP_file, std::ios::binary);
	if(!in3.is_open()){
		printf("Error.. Could not open the Graph Index File: %s", graphAdjListAndFP_file.c_str());
		return false;
	}

	// Reading the Graph Metadata File
	GraphMedataData objGrapMetaData;
	ifstream in4(graphMetadata_file, std::ios::binary);
	if(!in4.is_open()){
		printf("Error.. Could not open the Metadata File: %s\n", graphMetadata_file.c_str());
		return false;
	}

	// Load Graph Metadata first
	in4.read((char*)&objGrapMetaData, sizeof(GraphMedataData));
	cout << "Metadata : " << objGrapMetaData.ullMedoid << ", " << objGrapMetaData.ulluIndexEntryLen  << ", " << objGrapMetaData.uDatatype  <<
	", " << objGrapMetaData.uDim << ", " << objGrapMetaData.uDegree << ", " << objGrapMetaData.uDatasetSize << endl;

	m_objInputData.MEDOID = objGrapMetaData.ullMedoid;
	m_objInputData.D = objGrapMetaData.uDim;;
	m_objInputData.R = objGrapMetaData.uDegree;
	m_objInputData.N = objGrapMetaData.uDatasetSize;
	m_objInputData.ullIndex_Entry_LEN = objGrapMetaData.ulluIndexEntryLen;


	// Loading PQTable (binary)
	float *pqTable = NULL;
	float *pqTable_T  = NULL;
	unsigned *chunksOffset = NULL;
	float *centroid = NULL;
	uint8_t* compressedVectors = NULL;
	//uint64_t numr = 0;
	//uint64_t numc = 0;
	unsigned int N = 0;
	unsigned int uChunks = 0;
	unsigned* puNeighbour = NULL; // Very first neighbour
	unsigned* puNeighbour1 = NULL; // Very Last neighbour
	unsigned *puNumNeighbours = NULL;
	unsigned *puNumNeighbours1 = NULL;
	unsigned uNumPQSectionOffsets = 0;
	struct PQMetadata
	{
		unsigned long long pqPivots_FileOffset ;
		unsigned long long pqCentroid_FileOffset ;
		unsigned long long pqChunkOffsets_FileOffset ;
		unsigned long long pqPivots_FileSize;
	};

	PQMetadata pqFileOffsets = {0,0,0,0};
	// Loading PQ Compressed Vector (binary)

	in2.read((char*)&N, sizeof(int));
	cout << "Reading:" <<  compressedVector_file<< endl;
	cout << "No of points in Dataset = " << N	 << endl;
	in2.read((char*)&uChunks, sizeof(int));
	cout << "# PQ Chunks = " << uChunks << endl;
	m_objInputData.uChunks = uChunks;

	compressedVectors = (uint8_t*) malloc(sizeof(uint8_t) * uChunks * N);

	if (NULL == compressedVectors)
	{
		printf("Error.. Malloc failed for Compressed Vectors\n");
		bRet = false;
		goto cleanup;
	}

	in2.read((char*)compressedVectors, sizeof(uint8_t)*N*uChunks);
	in2.close();
	cout << "Finished reading bin file." << endl;
	// To reduce Peak Host memory usage, loading compressed vectors to CPU and transferring to GPU and releasing host memory
	printf("Transferring Compressed Vectors to GPU ...\n");
	gpuErrchk(cudaMalloc(&m_objInputData.d_compressedVectors, sizeof(uint8_t) * N * uChunks)); 	//100M*100 ~10GB
	gpuErrchk(cudaMemcpy(m_objInputData.d_compressedVectors, compressedVectors, (unsigned long long)(sizeof(uint8_t) * (unsigned long long)(uChunks)*N),
	cudaMemcpyHostToDevice));
	free(compressedVectors);
	compressedVectors = NULL;

	// Read the file offsets to the various sections in the PQ Pivots file
	in1.read((char*)&uNumPQSectionOffsets,sizeof(unsigned));
	if (uNumPQSectionOffsets != PQ_PIVOTS_NUM_SECTIONS+1)
	{
		printf("Error.. PQ Pivots File does not contain the required # of sub-sections:\n");
		return false;		
	}
	in1.seekg(4);

	in1.seekg(8,std::ios::beg);
	in1.read((char*)&pqFileOffsets,sizeof(PQMetadata));

	/*cout << "PD File Offsets read from PQ Pivots file:" <<
	"PQ Pivots FileOffset:" << pqFileOffsets.pqPivots_FileOffset << "\n" << 
	"PQ Centroids FileOffset:" << pqFileOffsets.pqCentroid_FileOffset << "\n" << 
	"PQ Centroids FileOsize:" << pqFileOffsets.pqCentroid_FileOffset << "\n" << 
	"PQ Pivots FileSize:" << pqFileOffsets.pqPivots_FileSize << endl;*/

	in1.seekg(pqFileOffsets.pqPivots_FileOffset+8,std::ios::beg);
	pqTable = (float*) malloc(sizeof(float) * (256 * m_objInputData.D)); // Contains pivot coordinates
	if (NULL == pqTable)
	{
		printf("Error.. Malloc failed PQ Table\n");
		return false;
	}
	in1.read((char*)pqTable,sizeof(float)*256*m_objInputData.D);

	// transpose pqTable
	pqTable_T = (float*) malloc(sizeof(float) * (256 * m_objInputData.D));
	if (NULL == pqTable_T)
	{
		printf("Error.. Malloc failed PQ Table Transpose\n");
		bRet = false;
		goto cleanup;
	}

	for(unsigned row = 0; row < 256; ++row) {
		for(unsigned col = 0; col < m_objInputData.D; ++col) {
			pqTable_T[col* 256 + row] = pqTable[row*m_objInputData.D+col];
		}
	}	

	// Loading centroid coordinates
	in1.seekg(pqFileOffsets.pqCentroid_FileOffset+8,std::ios::beg);
	centroid = (float*) malloc(sizeof(float) * ( m_objInputData.D)); 
	in1.read((char*)centroid,sizeof(float)*m_objInputData.D);


	// Loading chunk offsets
	in1.seekg(pqFileOffsets.pqChunkOffsets_FileOffset+8,std::ios::beg);
	chunksOffset = (unsigned*) malloc(sizeof(unsigned) * ( m_objInputData.uChunks+1)); 
	in1.read((char*)chunksOffset,sizeof(unsigned)*m_objInputData.uChunks+1);
	//cout << "Loaded:" <<  chunkOffsets_file << endl;

	in1.close();
	cout << "Finished reading :" << pqPivots_file << endl;
	
	gpuErrchk(cudaMalloc(&m_objInputData.d_pqTable, sizeof(float) * (256*m_objInputData.D)));
	gpuErrchk(cudaMalloc(&m_objInputData.d_chunksOffset, sizeof(unsigned) * (m_objInputData.uChunks+1)));
	gpuErrchk(cudaMalloc(&m_objInputData.d_centroid, sizeof(float) * (m_objInputData.D)));

	// host to device transfer
	gpuErrchk(cudaMemcpy(m_objInputData.d_pqTable, pqTable_T, sizeof(float) * (256*m_objInputData.D), cudaMemcpyHostToDevice));
	gpuErrchk(cudaMemcpy(m_objInputData.d_chunksOffset, chunksOffset, sizeof(unsigned) * (m_objInputData.uChunks+1), cudaMemcpyHostToDevice));
	gpuErrchk(cudaMemcpy(m_objInputData.d_centroid, centroid, sizeof(float) * (m_objInputData.D), cudaMemcpyHostToDevice));

	// Load the Vamana(DiskANN) Graph Index
	m_objInputData.size_indexfile  = caclulate_filesize(graphAdjListAndFP_file.c_str());
	m_objInputData.pIndex = (uint8_t*)malloc(m_objInputData.size_indexfile);
	if (NULL == m_objInputData.pIndex)
	{
		printf("Error.. Malloc failed for Graph Index.\n");
		gpuErrchk(cudaFree(m_objInputData.d_compressedVectors));
		gpuErrchk(cudaFree(&m_objInputData.d_pqTable));
		gpuErrchk(cudaFree(&m_objInputData.d_chunksOffset));
		gpuErrchk(cudaFree(&m_objInputData.d_centroid));
		bRet = false;
		goto cleanup;
	}

	log_message("Index Load Started");
	in3.read((char*)m_objInputData.pIndex, m_objInputData.size_indexfile);
	log_message("Index Load Done");
	in3.close();

	// Sanity test start
	// to see if the Index file was loaded properly
	// Read the first and last neighbour

	// First neighbour calculation
	puNumNeighbours = (unsigned*)(m_objInputData.pIndex+((m_objInputData.ullIndex_Entry_LEN*0)+ (sizeof(T)*m_objInputData.D) ));
	puNeighbour = puNumNeighbours + 1;

	// Last neighbour calculation
	puNumNeighbours1 = (unsigned*)(m_objInputData.pIndex + ( (m_objInputData.ullIndex_Entry_LEN * (m_objInputData.N-1)) + (sizeof(T)*m_objInputData.D) )) ;
	puNeighbour1 = puNumNeighbours1 + (*puNumNeighbours1) ;
	// Print the first and last neighbour in AdjList
	printf("First Neighbour : %u \t Last Neighbour: %u\n", *puNeighbour, *puNeighbour1);

	assert (*puNeighbour <= m_objInputData.N);
	assert (*puNeighbour1 <= m_objInputData.N);
	// Sanity test end

	cout << "Graph Medoid is : " << m_objInputData.MEDOID << "\t"  << endl;
	cout << "BF Size : " << BF_ENTRIES << "\t"  << endl;


cleanup:
	free(pqTable);
	pqTable = NULL;
	free(pqTable_T);
	pqTable_T = NULL;
	free(chunksOffset);
	chunksOffset = NULL;
	free(centroid);
	centroid = NULL;
	return bRet;
}



template<typename T>
void BANGSearchInner<T>::bang_alloc(int numQueries)
{
	// Assignments needed for determining allocation sizes
	const unsigned uMAX_PARENTS_PERQUERY = (m_objSearchParams.worklist_length + NAX_EXTRA_ITERATION) ;
	m_objHostInst.FPSetCoords_size = m_objInputData.D  ;
	m_objHostInst.FPSetCoords_size_bytes = m_objHostInst.FPSetCoords_size * sizeof(T);
	m_objHostInst.FPSetCoords_rowsize = m_objHostInst.FPSetCoords_size * numQueries;
	m_objHostInst.FPSetCoords_rowsize_bytes = m_objHostInst.FPSetCoords_size_bytes * numQueries;


	// Allocations on GPU
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_queriesFP, sizeof(T) * (numQueries*m_objInputData.D)));
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_nearestNeighbours, (m_objSearchParams.recall * numQueries) * sizeof(result_ann_t) ));// Dim: [recall_at * numQueries]
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_pqDistTables, sizeof(float) * (256*m_objInputData.uChunks*numQueries)));
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_BestLSetsDist, sizeof(float) * (numQueries*(m_objSearchParams.worklist_length))));
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_BestLSets_count, sizeof(unsigned) * (numQueries)));
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_BestLSets_visited, sizeof(bool) * (numQueries* (m_objSearchParams.worklist_length))));
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_BestLSets, sizeof(unsigned) * (numQueries* (m_objSearchParams.worklist_length))));
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_parents, sizeof(unsigned) * (numQueries*(SIZEPARENTLIST))));
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_neighbors, sizeof(unsigned) * (numQueries*(m_objInputData.R+1))));
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_neighbors_temp, sizeof(unsigned) * (numQueries*(m_objInputData.R+1))));
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_neighbors_aux, sizeof(unsigned) * (numQueries*(m_objInputData.R+1))));
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_numNeighbors_query, sizeof(unsigned) * (numQueries)));
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_numNeighbors_query_temp, sizeof(unsigned) * (numQueries)));
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_neighborsDist_query, sizeof(float) * (numQueries*(m_objInputData.R+1))));
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_neighborsDist_query_aux, sizeof(float) * (numQueries*(m_objInputData.R+1))));
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_processed_bit_vec, sizeof(bool)*BF_MEMORY*numQueries));
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_nextIter, sizeof(bool)));
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_iter, sizeof(unsigned)));
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_mark, sizeof(unsigned) * (numQueries)));			// ~40KB
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_FPSetCoordsList_Counts, numQueries * sizeof(unsigned) ));
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_FPSetCoordsList, (uMAX_PARENTS_PERQUERY * numQueries) * m_objHostInst.FPSetCoords_size_bytes )); // Dim: [numIterations * numQueries]
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_L2distances, (uMAX_PARENTS_PERQUERY * numQueries) * sizeof(float) )); // Dim: [numIterations * numQueries]
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_L2ParentIds, (uMAX_PARENTS_PERQUERY * numQueries) * sizeof(unsigned) )); // Dim: [numIterations * numQueries]
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_L2distances_aux, (uMAX_PARENTS_PERQUERY * numQueries) * sizeof(float) )); // Dim: [numIterations * numQueries]
	gpuErrchk(cudaMalloc(&m_objGPUInst.d_L2ParentIds_aux, (uMAX_PARENTS_PERQUERY * numQueries) * sizeof(unsigned) )); // Dim: [numIterations * numQueries]

	// Default stream computations or transfers cannot be overalapped with operations on other streams
	// Hence creating separate streams for transfers and computations to achieve overlap
	// memory transfers overlap with all kernel executions
	gpuErrchk(cudaStreamCreate(&m_objGPUInst.streamFPTransfers));
	gpuErrchk(cudaStreamCreate(&m_objGPUInst.streamParent));
	gpuErrchk(cudaStreamCreate(&m_objGPUInst.streamChildren));
	gpuErrchk(cudaStreamCreate(&m_objGPUInst.streamKernels));

	// Host size params
	m_objHostInst.numCPUthreads = 64;//64 // ToDo: get this dynamically from the platform

	// Host Memory Allocation
	gpuErrchk(cudaMallocHost(&m_objHostInst.neighbors, sizeof(unsigned) * (numQueries*(m_objInputData.R+1))) );
	// Note : R+1 is needed because MEDOID is added as additional neighbour in very first neighbour fetching (iteration)
	gpuErrchk(cudaMallocHost(&m_objHostInst.numNeighbors_query,sizeof(unsigned) * (numQueries) ));
	gpuErrchk(cudaMallocHost(&m_objHostInst.parents,sizeof(unsigned) * numQueries * (SIZEPARENTLIST)));
	//m_objHostInst.L2ParentIds = (unsigned*)malloc(sizeof(unsigned) * numQueries);
	//m_objHostInst.FPSetCoordsList_Counts = (unsigned*)malloc(sizeof(unsigned) * numQueries);
	gpuErrchk(cudaMallocHost(&m_objHostInst.FPSetCoordsList, (uMAX_PARENTS_PERQUERY * numQueries) * m_objHostInst.FPSetCoords_size_bytes));
}

// Note:To be called after setSearchparams
// Set-up params and pre-compute as much we can before the actural query processing can begin
template<typename T>
void BANGSearchInner<T>::bang_init(int numQueries)
{

	// Initialize GPU related attributes
	m_objGPUInst.numThreads_K4 = 1; //	compute_parent kernel
	m_objGPUInst.numThreads_K1 = 256;//	populate_pqDist_par
	m_objGPUInst.numThreads_K2 = 512;// compute_neighborDist_par
	m_objGPUInst.numThreads_K3 = m_objInputData.R+1;
	m_objGPUInst.K4_blockSize = 256;
	m_objGPUInst.numThreads_K5 =256;// neighbor_filtering_new
	m_objGPUInst.numThreads_K3_merge = 2*m_objSearchParams.worklist_length;
	assert(m_objGPUInst.numThreads_K3_merge <= 1024);	// Max thread block size
	gpuErrchk(cudaMemset(m_objGPUInst.d_iter,0,sizeof(unsigned)));

	gpuErrchk(cudaMemset(m_objGPUInst.d_pqDistTables,0,sizeof(float) * (m_objInputData.uChunks * 256 * numQueries)));
	gpuErrchk(cudaMemset(m_objGPUInst.d_processed_bit_vec, 0, sizeof(bool)*BF_MEMORY*numQueries));
	gpuErrchk(cudaMemset(m_objGPUInst.d_parents, 0, sizeof(unsigned)*(numQueries*(SIZEPARENTLIST))));
	gpuErrchk(cudaMemset(m_objGPUInst.d_BestLSets_count, 0, sizeof(unsigned)*(numQueries)));
	gpuErrchk(cudaMemset(m_objGPUInst.d_mark, 1, sizeof(unsigned)*(numQueries))); // ToDo, should be 0?
	gpuErrchk(cudaMemset(m_objGPUInst.d_neighborsDist_query,0,sizeof(float) * (numQueries*(m_objInputData.R+1))));

	// As we know the Medoid is the first parent, lets get started with working extracting its neighbours
	T* FPSetCoordsList = (T*)m_objHostInst.FPSetCoordsList;
	T* d_FPSetCoordsList = (T*)m_objGPUInst.d_FPSetCoordsList;
	unsigned* L2ParentIds = (unsigned*)malloc(sizeof(unsigned) * numQueries);
	unsigned* FPSetCoordsList_Counts = (unsigned*)malloc(sizeof(unsigned) * numQueries);
	// Very first iteration starts with Medoid as the parent/candidate in all Queries
	for (int i = 0 ; i < numQueries; i++)
	{
		L2ParentIds[i] = m_objInputData.MEDOID;
		FPSetCoordsList_Counts[i] = 1;
	}
	// Transfer the Medoid (seed parent) default first parent
	gpuErrchk(cudaMemcpy(m_objGPUInst.d_L2ParentIds, L2ParentIds, sizeof(unsigned) * numQueries, cudaMemcpyHostToDevice ));
	gpuErrchk(cudaMemcpy(m_objGPUInst.d_FPSetCoordsList_Counts, FPSetCoordsList_Counts, sizeof(unsigned) * numQueries, cudaMemcpyHostToDevice ));
	free(L2ParentIds);
	free(FPSetCoordsList_Counts);

// ToDo: Fetching the neighbours of Medoid and transferring them to GPU can be moved to Load Phase
	unsigned* puNumNeighbours = (unsigned*)( m_objInputData.pIndex + ((m_objInputData.ullIndex_Entry_LEN * m_objInputData.MEDOID)
								+ (m_objInputData.D*sizeof(T))) );

	unsigned medoidDegree = *puNumNeighbours;
	unsigned* puNeighbour = puNumNeighbours + 1;
	vector<unsigned> medoidNeighbors;
	unsigned uMaxNeighbors =  m_objInputData.R+1;
	for(unsigned long long ii = 0; ii < medoidDegree; ++ii)
	{
		medoidNeighbors.push_back(puNeighbour[ii]);
	}

	unsigned iter = 1; // Note 1-based not 0
	// [2] Setting the neighbors of medoid as initial candidate neighbors for the query point
	for(unsigned ii=0; ii < numQueries; ++ii ) {
		m_objHostInst.neighbors[ii * uMaxNeighbors] = m_objInputData.MEDOID; // conside medoid also as initial neighbour
		unsigned numNeighbors = 1; // medoid is already inserted
		for (unsigned i = 0; i < medoidDegree; ++i) {
			m_objHostInst.neighbors[ii * uMaxNeighbors + i + 1] = medoidNeighbors[i];
			numNeighbors++;
		}

		m_objHostInst.numNeighbors_query[ii] = numNeighbors;

		// Copy the medoid's FP vectors Async (row 0) iter = 1 here.
		memcpy(FPSetCoordsList + ((iter-1) * m_objHostInst.FPSetCoords_rowsize) + (ii*m_objHostInst.FPSetCoords_size),
				m_objInputData. pIndex + (m_objInputData.ullIndex_Entry_LEN * m_objInputData.MEDOID) ,
				m_objHostInst.FPSetCoords_size_bytes);
	}

	// 0th row in FPSetCoordsListget copied to GPU in Async fashion
	cudaMemcpy(d_FPSetCoordsList + ((iter-1) * m_objHostInst.FPSetCoords_rowsize),
					FPSetCoordsList + ((iter-1)* m_objHostInst.FPSetCoords_rowsize),
					m_objHostInst.FPSetCoords_rowsize_bytes,
					cudaMemcpyHostToDevice);


	// Transfer neighbor IDs and count to GPU
	gpuErrchk(cudaMemcpy(m_objGPUInst.d_neighbors_temp, m_objHostInst.neighbors, sizeof(unsigned) * numQueries*(m_objInputData.R+1), cudaMemcpyHostToDevice));
	gpuErrchk(cudaMemcpy(m_objGPUInst.d_numNeighbors_query_temp, m_objHostInst.numNeighbors_query, sizeof(unsigned) * (numQueries), cudaMemcpyHostToDevice));
}

template<typename T>
void BANGSearchInner<T>::bang_free()
{
	gpuErrchk(cudaFree(m_objGPUInst.d_queriesFP));
	gpuErrchk(cudaFree(m_objGPUInst.d_nearestNeighbours));
	gpuErrchk(cudaFree(m_objGPUInst.d_pqDistTables));
	gpuErrchk(cudaFree(m_objGPUInst.d_BestLSetsDist));
	gpuErrchk(cudaFree(m_objGPUInst.d_BestLSets_visited));
	gpuErrchk(cudaFree(m_objGPUInst.d_BestLSets_count));
	gpuErrchk(cudaFree(m_objGPUInst.d_BestLSets));
	gpuErrchk(cudaFree(m_objGPUInst.d_parents));
	gpuErrchk(cudaFree(m_objGPUInst.d_neighbors));
	gpuErrchk(cudaFree(m_objGPUInst.d_neighbors_temp));
	gpuErrchk(cudaFree(m_objGPUInst.d_neighbors_aux));
	gpuErrchk(cudaFree(m_objGPUInst.d_numNeighbors_query));
	gpuErrchk(cudaFree(m_objGPUInst.d_numNeighbors_query_temp));
	gpuErrchk(cudaFree(m_objGPUInst.d_neighborsDist_query));
	gpuErrchk(cudaFree(m_objGPUInst.d_neighborsDist_query_aux));
	gpuErrchk(cudaFree(m_objGPUInst.d_processed_bit_vec));
	gpuErrchk(cudaFree(m_objGPUInst.d_nextIter));
	gpuErrchk(cudaFree(m_objGPUInst.d_iter));
	gpuErrchk(cudaFree(m_objGPUInst.d_mark));
	gpuErrchk(cudaFree(m_objGPUInst.d_FPSetCoordsList_Counts));
	gpuErrchk(cudaFree(m_objGPUInst.d_FPSetCoordsList));
	gpuErrchk(cudaFree(m_objGPUInst.d_L2distances));
	gpuErrchk(cudaFree(m_objGPUInst.d_L2ParentIds));
	gpuErrchk(cudaFree(m_objGPUInst.d_L2distances_aux));
	gpuErrchk(cudaFree(m_objGPUInst.d_L2ParentIds_aux));


	cudaStreamDestroy(m_objGPUInst.streamFPTransfers);
	cudaStreamDestroy(m_objGPUInst.streamKernels);
	cudaStreamDestroy(m_objGPUInst.streamParent);
	cudaStreamDestroy(m_objGPUInst.streamChildren);

	gpuErrchk(cudaFreeHost(m_objHostInst.neighbors));
	gpuErrchk(cudaFreeHost(m_objHostInst.numNeighbors_query));
	gpuErrchk(cudaFreeHost(m_objHostInst.parents));
	gpuErrchk(cudaFreeHost(m_objHostInst.FPSetCoordsList));
}

template<typename T>
void BANGSearchInner<T>::bang_unload()
{
	printf("Bang Unload \n");
	free(m_objInputData.pIndex);
	gpuErrchk(cudaFree(m_objInputData.d_compressedVectors));
	gpuErrchk(cudaFree(m_objInputData.d_pqTable));
	gpuErrchk(cudaFree(m_objInputData.d_chunksOffset));
	gpuErrchk(cudaFree(m_objInputData.d_centroid));
}

template<typename T>
void BANGSearchInner<T>::bang_set_searchparams(int recall, int worklist_length, DistFunc nDistFunc)
{
	m_objSearchParams.recall = recall;
	m_objSearchParams.worklist_length = worklist_length;
	m_objSearchParams.uDistFunc = nDistFunc;
}

template<typename T>
void BANGSearchInner<T>::bang_query(T* queriesFP, int numQueries,
					result_ann_t* nearestNeighbours,
					float* nearestNeighbours_dist )
{

	T* FPSetCoordsList = (T*) m_objHostInst.FPSetCoordsList;
	T *d_queriesFP = (T*)m_objGPUInst.d_queriesFP;
	T* d_FPSetCoordsList = (T*)m_objGPUInst.d_FPSetCoordsList; // M x N

#ifdef _TIMERS
	// GPU execution times
	double time_transfer = 0.0f;
	double time_K1 = 0.0f;
	double time_B1 = 0.0f;
	double time_B2 = 0.0f;
	double time_neighbor_filtering = 0.0f;
	double time_prfetch	= 0.0f;
	// CPU execution times
	double fp_set_time_gpu = 0.0f; // GPU side
	double seek_neighbours_time = 0.0f;
	vector<double> time_B1_vec;
	vector<double> time_B2_vec;
	time_B2_vec.push_back(0.0);
#endif

	bool nextIter = false;
	unsigned iter = 1; // Note 1-based not 0
	//unsigned uMaxNeighbors =  (m_objInputData.R+1);

#ifdef _TIMERS
	GPUTimer gputimer (m_objGPUInst.streamKernels, false);	// Initiating the GPUTimer class object
#endif

	const unsigned uMAX_PARENTS_PERQUERY = (m_objSearchParams.worklist_length + NAX_EXTRA_ITERATION) ; //Needs to be set with expereince. set it to (2*L) if in doubt

	omp_set_num_threads(m_objHostInst.numCPUthreads);

	#ifdef _TIMERS
	auto milliStart = log_message("SEARCH STARTED");
	auto start = std::chrono::high_resolution_clock::now();
	#endif
	// ToDo: Check the Dim of queriesFP == m_objInputData.D, for mips, Dimentionality of queriesFP +1 = m_objInputData.D
	gpuErrchk(cudaMemcpy(d_queriesFP, queriesFP, sizeof(T) * (m_objInputData.D*numQueries), cudaMemcpyHostToDevice));

#ifdef _TIMERS
	auto stop = std::chrono::high_resolution_clock::now();
	time_transfer += std::chrono::duration_cast<std::chrono::nanoseconds>(stop-start).count() / 1000.0;
	gputimer.Start();
#endif
	/**
	 * [3] Launching the kernel with "numQueries" number of thread-blocks and user specified "numThreads_K1" block size.
	 * One thread block is assigned to a query, i.e., "numThreads_K1" threads perform the computation for a query.
	 */
	populate_pqDist_par<<<numQueries, m_objGPUInst.numThreads_K1, (m_objInputData.D*(sizeof(float)+sizeof(T))), m_objGPUInst.streamKernels>>> (
							m_objInputData.d_pqTable,
							m_objGPUInst.d_pqDistTables,
							d_queriesFP,
							m_objInputData.d_chunksOffset,
							m_objInputData.d_centroid,
							m_objInputData.uChunks,
							m_objInputData.D,
							m_objSearchParams.uDistFunc == ENUM_DIST_MIPS ? MIPS_EXTRA_DIM : 0);
#ifdef _TIMERS
	gputimer.Stop();
	time_K1 += gputimer.Elapsed();
	start = std::chrono::high_resolution_clock::now();
#endif

	gpuErrchk(cudaMemset(m_objGPUInst.d_numNeighbors_query, 0, sizeof(unsigned)*numQueries));

#ifdef _TIMERS
	stop = std::chrono::high_resolution_clock::now();
	time_transfer += std::chrono::duration_cast<std::chrono::nanoseconds>(stop-start).count() / 1000.0;
	gputimer.Start();
#endif

	/** [4] Launching the kernel with "numQueries" number of thread-blocks and block size of 256
	 * One thread block is assigned to a query, i.e., 256 threads perform the computation for a query. The block size has been tuned for performance.
	 */

	neighbor_filtering_new<<<numQueries, m_objGPUInst.numThreads_K5, 0, m_objGPUInst.streamKernels >>> (m_objGPUInst.d_neighbors, m_objGPUInst.d_neighbors_temp, m_objGPUInst.d_numNeighbors_query,
				m_objGPUInst.d_numNeighbors_query_temp, m_objGPUInst.d_processed_bit_vec,m_objInputData.R);

#ifdef _TIMERS
	gputimer.Stop();
	time_neighbor_filtering += gputimer.Elapsed() ;

	gputimer.Start();
#endif

	/** [5] Launching the kernel with "numQueries" number of thread-blocks and user specified "numThreads_K2" block size.
	 * One thread block is assigned to a query, i.e., "numThreads_K2" threads perform the computation for a query.
	 */
	compute_neighborDist_par <<<numQueries, m_objGPUInst.numThreads_K2,0, m_objGPUInst.streamKernels >>> (m_objGPUInst.d_neighbors, m_objGPUInst.d_numNeighbors_query, m_objInputData.d_compressedVectors,
	m_objGPUInst.d_pqDistTables, m_objGPUInst.d_neighborsDist_query, m_objInputData.uChunks, m_objInputData.R);

	gpuErrchk(cudaMemcpyAsync(m_objGPUInst.d_iter, &iter, sizeof(unsigned), cudaMemcpyHostToDevice, m_objGPUInst.streamKernels));

#ifdef _TIMERS
	gputimer.Stop();
	time_B1_vec.push_back(gputimer.Elapsed());
	gputimer.Start();
#endif
	/** [6] Launching the kernel with "X" number of thread-blocks and block size of one. X is calculated below
	 * A single threads perform the computation for a query.
	 * Note: The  additional arithmetic in the number of thread blocks it to arrive a ceil value. After assigning a required value
	 * to numThreads_K4, the division could leat to a truncated quotient, resulting in lesser than expected thread blocks getting spawned.
	 */
	compute_parent1<<<(numQueries + m_objGPUInst.numThreads_K4 -1 )/m_objGPUInst.numThreads_K4,m_objGPUInst.numThreads_K4,0, m_objGPUInst.streamKernels >>>
						(m_objGPUInst.d_neighbors,
						m_objGPUInst.d_numNeighbors_query,
						m_objGPUInst.d_neighborsDist_query,
						m_objGPUInst.d_BestLSets,
						m_objGPUInst.d_BestLSetsDist,
						m_objGPUInst.d_BestLSets_visited,
						m_objGPUInst.d_parents,
						m_objGPUInst.d_nextIter,
						m_objGPUInst.d_BestLSets_count,
						m_objGPUInst.d_mark,
						m_objGPUInst.d_iter,
						m_objGPUInst.d_L2ParentIds,
						m_objGPUInst.d_FPSetCoordsList_Counts,
						numQueries,
						m_objInputData.MEDOID,
						m_objInputData.R);
	cudaStreamSynchronize(m_objGPUInst.streamKernels);
#ifdef _TIMERS
	gputimer.Stop();
	time_prfetch += gputimer.Elapsed();
#endif
	// Loop until all the query have no new parents/candidates
	do
	{

#ifdef _TIMERS
		start = std::chrono::high_resolution_clock::now();
#endif

		// Transfer parent IDs from GPU to CPU
		gpuErrchk(cudaMemcpyAsync(m_objHostInst.parents, m_objGPUInst.d_parents, sizeof(unsigned) * ((SIZEPARENTLIST)*numQueries),
									cudaMemcpyDeviceToHost,
									m_objGPUInst.streamParent));

#ifdef _TIMERS
		stop = std::chrono::high_resolution_clock::now();
		time_transfer += std::chrono::duration_cast<std::chrono::nanoseconds>(stop-start).count() / 1000.0;;
		gputimer.Start();
#endif
		/** [8] Launching the kernel with "numQueries" number of thread-blocks and (R+1) block size.
		 * One thread block is assigned to a query, i.e., (R+1) threads perform the computation for a query.
		 * The kernel  sorts an array of size (R+1) per query, so we require (R+1) threads per query.
		 */
#ifdef _NO_PRETECH
		if (iter == 1)
#endif
		{
		compute_BestLSets_par_sort_msort<<<numQueries, m_objGPUInst.numThreads_K3,0, m_objGPUInst.streamKernels >>>(m_objGPUInst.d_neighbors,
															m_objGPUInst.d_neighbors_aux,
															m_objGPUInst.d_numNeighbors_query,
															m_objGPUInst.d_neighborsDist_query,
															m_objGPUInst.d_neighborsDist_query_aux,
															m_objGPUInst.d_nextIter, m_objInputData.R);

		/** [9] Launching the kernel with "numQueries" number of thread-blocks and (2*L) block size.
		 * One thread block is assigned to a query, i.e., (2*L) threads perform the computation for a query.
		 * The kernel merges, for every query, two arrays each of whose sizes are upperbounded by L,
		 * so we require 2*L threads per query.
		 */
		compute_BestLSets_par_merge<<<numQueries, m_objGPUInst.numThreads_K3_merge, (m_objInputData.R+1)*sizeof(float), m_objGPUInst.streamKernels >>>(m_objGPUInst.d_neighbors,
										m_objGPUInst.d_numNeighbors_query,
										m_objGPUInst.d_neighborsDist_query,
										m_objGPUInst.d_BestLSets,
										m_objGPUInst.d_BestLSetsDist,
										m_objGPUInst.d_BestLSets_visited,
										m_objGPUInst.d_parents,
										iter,
										m_objGPUInst.d_nextIter,
										m_objGPUInst.d_BestLSets_count,
										m_objGPUInst.d_mark,
										m_objSearchParams.worklist_length,
										m_objInputData.MEDOID,
										m_objInputData.R);
		}


#ifdef _TIMERS
		gputimer.Stop();
		time_B2_vec.push_back(gputimer.Elapsed());
		start = std::chrono::high_resolution_clock::now();
#endif
		// Note: This init is very much required. Though it gets updated later but that update does not happen for queries which don't yield parents
		memset(m_objHostInst.numNeighbors_query, 0, sizeof(unsigned) * numQueries	);

		cudaStreamSynchronize(m_objGPUInst.streamParent);

#ifdef _TIMERS
		stop = std::chrono::high_resolution_clock::now();
		time_transfer += std::chrono::duration_cast<std::chrono::nanoseconds>(stop-start).count() / 1000.0;
		start = std::chrono::high_resolution_clock::now();
#endif
		unsigned offset =  (m_objInputData.R+1); // max no of neigbours for a given parent. ToDo : can it be R here? as Medoid is not in picture
		#pragma omp parallel
		{
			// NOTE: USE STACK VARIABLES TO AVOID CONCURRENCY ISSUES
			int CPUthreadno =  omp_get_thread_num();

			/*Collecting the node ids of neighborhood of the parent nodes to send to GPU */
			// Note: Only one parent is supported per query. Becasue offset_neighbors is function of
			// queryID only. To support multiple parents in a query, it should also consider the parent number(jj) within a query
			for(unsigned ii=CPUthreadno; ii < numQueries; ii = ii + m_objHostInst.numCPUthreads)
			{
				unsigned numParents = m_objHostInst.parents[ii*(SIZEPARENTLIST)];

				#ifdef _DBG_BOUNDS
				if (numParents > 1)
					printf("ERROR : numParents of %u iter=%u\n", numParents, iter);
				#endif

				for(unsigned jj = 1; jj <= numParents; ++jj) //numParents is 1 today
				{
					unsigned curreParent = m_objHostInst.parents[ii*(SIZEPARENTLIST)+jj];;


					unsigned offset_neighbors = ii * offset;

					// Copy the Parent's'FP vectors of current query
					memcpy(FPSetCoordsList + (iter * m_objHostInst.FPSetCoords_rowsize) + (ii*m_objHostInst.FPSetCoords_size),
							m_objInputData.pIndex + (m_objInputData.ullIndex_Entry_LEN * curreParent),
							m_objHostInst.FPSetCoords_size_bytes);

					// Extract Neighbour
					unsigned *puNumNeighbours = (unsigned*)(m_objInputData.pIndex + ((m_objInputData.ullIndex_Entry_LEN*curreParent)+(sizeof(T)*m_objInputData.D)) );;

					#ifdef _DBG_BOUNDS
					// validation
					if (*puNumNeighbours > m_objInputData.R)
						printf("*** ERROR: NumNeighbours %d which is > R \n",*puNumNeighbours);
					#endif

					memcpy(m_objHostInst.neighbors+offset_neighbors, puNumNeighbours+1, (*puNumNeighbours) * sizeof(unsigned));
					m_objHostInst.numNeighbors_query[ii] = (*puNumNeighbours);
				}
			}
		}
		// Lets wait for the two kernels to complete in parallel.
#ifdef _TIMERS
	    auto stop = std::chrono::high_resolution_clock::now();

		seek_neighbours_time += std::chrono::duration_cast<std::chrono::nanoseconds>(stop-start).count() / 1000.0;

		// Lets wait for the previous two kernels to complete in parallel to CPU operations. Elapsed() is a blocking call
		// Waiting is only for stats and not really need for the functionality


		start = std::chrono::high_resolution_clock::now();
		// Transfer unfiltered neighbors from CPU to GPU
#endif
		gpuErrchk(cudaMemcpyAsync(m_objGPUInst.d_neighbors_temp, m_objHostInst.neighbors, sizeof(unsigned) * numQueries*(m_objInputData.R+1),
									cudaMemcpyHostToDevice,
									m_objGPUInst.streamChildren));

		gpuErrchk(cudaMemcpyAsync(m_objGPUInst.d_numNeighbors_query_temp, m_objHostInst.numNeighbors_query, sizeof(unsigned) * (numQueries),
									cudaMemcpyHostToDevice,
									m_objGPUInst.streamChildren));

		// Transfer the FP vectors also from CPU to GPU in Async fashion
		cudaMemcpyAsync(d_FPSetCoordsList + (iter * m_objHostInst.FPSetCoords_rowsize),
					FPSetCoordsList + (iter * m_objHostInst.FPSetCoords_rowsize),
					m_objHostInst.FPSetCoords_rowsize_bytes, cudaMemcpyHostToDevice, m_objGPUInst.streamFPTransfers);

#ifdef _NO_ASYNC_FP
		cudaStreamSynchronize(m_objGPUInst.streamFPTransfers);
#endif

		gpuErrchk(cudaMemsetAsync(m_objGPUInst.d_numNeighbors_query, 0, sizeof(unsigned)*numQueries, m_objGPUInst.streamChildren));
		cudaStreamSynchronize(m_objGPUInst.streamChildren);
#ifdef _TIMERS
		stop = std::chrono::high_resolution_clock::now();
		time_transfer += std::chrono::duration_cast<std::chrono::nanoseconds>(stop-start).count() / 1000.0;

		gputimer.Start();
#endif
		/** [11] Launching the kernel with "numQueries" number of thread-blocks and block size of 256
		 * One thread block is assigned to a query, i.e., 256 threads perform the computation for a query. The block size has been tuned for performance.
		 */
		neighbor_filtering_new<<<numQueries, m_objGPUInst.numThreads_K5,0, m_objGPUInst.streamKernels >>> (m_objGPUInst.d_neighbors,
																		m_objGPUInst.d_neighbors_temp,
																		m_objGPUInst.d_numNeighbors_query,
																		m_objGPUInst.d_numNeighbors_query_temp,
																		m_objGPUInst.d_processed_bit_vec, m_objInputData.R);
#ifdef _TIMERS
		gputimer.Stop();
		time_neighbor_filtering += gputimer.Elapsed() ;

		gputimer.Start();
#endif
		gpuErrchk(cudaMemsetAsync(m_objGPUInst.d_neighborsDist_query,0,sizeof(float) * (numQueries*(m_objInputData.R+1)), m_objGPUInst.streamKernels ));

		/** [12]vLaunching the kernel with "numQueries" number of thread-blocks and user specified "numThreads_K2" block size.
		 * One thread block is assigned to a query, i.e., "numThreads_K2" threads perform the computation for a query.
		 */
		compute_neighborDist_par <<<numQueries, m_objGPUInst.numThreads_K2,0,m_objGPUInst.streamKernels >>> (m_objGPUInst.d_neighbors, m_objGPUInst.d_numNeighbors_query, m_objInputData.d_compressedVectors,
		m_objGPUInst.d_pqDistTables, m_objGPUInst.d_neighborsDist_query, m_objInputData.uChunks, m_objInputData.R);

#ifdef _TIMERS
		gputimer.Stop();
		time_B1_vec.push_back(gputimer.Elapsed());
		gputimer.Start();
#endif
		++iter;

		gpuErrchk(cudaMemcpyAsync(m_objGPUInst.d_iter, &iter, sizeof(unsigned), cudaMemcpyHostToDevice, m_objGPUInst.streamKernels));

#ifdef _NO_PRETECH
// No prefetch start
		compute_BestLSets_par_sort_msort<<<numQueries, m_objGPUInst.numThreads_K3,0, m_objGPUInst.streamKernels >>>(m_objGPUInst.d_neighbors,
															m_objGPUInst.d_neighbors_aux,
															m_objGPUInst.d_numNeighbors_query,
															m_objGPUInst.d_neighborsDist_query,
															m_objGPUInst.d_neighborsDist_query_aux,
															m_objGPUInst.d_nextIter, m_objInputData.R);

		/** [9] Launching the kernel with "numQueries" number of thread-blocks and (2*L) block size.
		 * One thread block is assigned to a query, i.e., (2*L) threads perform the computation for a query.
		 * The kernel merges, for every query, two arrays each of whose sizes are upperbounded by L,
		 * so we require 2*L threads per query.
		 */
		compute_BestLSets_par_merge<<<numQueries, m_objGPUInst.numThreads_K3_merge, (m_objInputData.R+1)*sizeof(float), m_objGPUInst.streamKernels >>>(m_objGPUInst.d_neighbors,
										m_objGPUInst.d_numNeighbors_query,
										m_objGPUInst.d_neighborsDist_query,
										m_objGPUInst.d_BestLSets,
										m_objGPUInst.d_BestLSetsDist,
										m_objGPUInst.d_BestLSets_visited,
										m_objGPUInst.d_parents,
										iter,
										m_objGPUInst.d_nextIter,
										m_objGPUInst.d_BestLSets_count,
										m_objGPUInst.d_mark,
										m_objSearchParams.worklist_length,
										m_objInputData.MEDOID,
										m_objInputData.R);
// No prefetch end
#endif
		/** [13] Launching the kernel with "X" number of thread-blocks and block size of one.
	 	* A songle threads perform the computation for a query.
		 */
		// previous d_iter would have transferred by now
		compute_parent2<<<(numQueries + m_objGPUInst.numThreads_K4 -1 )/m_objGPUInst.numThreads_K4,m_objGPUInst.numThreads_K4,0, m_objGPUInst.streamKernels >>>
				(m_objGPUInst.d_neighbors,
				m_objGPUInst.d_numNeighbors_query,
				m_objGPUInst.d_neighborsDist_query,
				m_objGPUInst.d_BestLSets,
				m_objGPUInst.d_BestLSetsDist,
				m_objGPUInst.d_BestLSets_visited,
				m_objGPUInst.d_parents,
				m_objGPUInst.d_nextIter,
				m_objGPUInst.d_BestLSets_count,
				m_objGPUInst.d_mark,
				m_objGPUInst.d_iter,
				m_objGPUInst.d_L2ParentIds,
				m_objGPUInst.d_FPSetCoordsList_Counts,
				numQueries,
				m_objSearchParams.worklist_length,
				m_objInputData.MEDOID,
				m_objInputData.R);


#ifdef _TIMERS
		gputimer.Stop();
		time_prfetch += gputimer.Elapsed();
		start = std::chrono::high_resolution_clock::now();
#endif
		gpuErrchk(cudaMemcpyAsync(&nextIter, m_objGPUInst.d_nextIter, sizeof(bool), cudaMemcpyDeviceToHost, m_objGPUInst.streamKernels));  //d_nextIter calculated in compute_parent<<< >>>
		cudaStreamSynchronize(m_objGPUInst.streamKernels);

#ifdef _TIMERS
		stop = std::chrono::high_resolution_clock::now();
		time_transfer += std::chrono::duration_cast<std::chrono::nanoseconds>(stop-start).count() / 1000.0;
#endif

		if (iter == uMAX_PARENTS_PERQUERY-1)
		{
			#ifdef _DBG_BOUNDS
			printf("Error: Iterations crossed the assumed limit. FPSetCoords size overrun \n");
			#endif
			break;
		}
	}
	while(nextIter);

	// Search Iterations Ends
	// Re-rnking start
#ifdef _TIMERS
	gputimer.Start();
#endif
	// Lets ensure we have received all the FP vectors before starting the Re-ranking.
	// We need FP vectors to calculate exact distances now. Compressed vectors are not used hereafter
	cudaStreamSynchronize(m_objGPUInst.streamFPTransfers);

	compute_L2Dist<<<numQueries, m_objGPUInst.K4_blockSize, m_objInputData.D * sizeof(T) >>> (d_FPSetCoordsList,
												m_objGPUInst.d_FPSetCoordsList_Counts,
												d_queriesFP,
												m_objGPUInst.d_L2ParentIds,
												m_objGPUInst.d_L2distances,
												numQueries,
												m_objInputData.D,
												m_objSearchParams.uDistFunc == ENUM_DIST_MIPS ? MIPS_EXTRA_DIM : 0);


	// We have the exact distances of each each candidate. Lets pick the topk neighbours.
	compute_NearestNeighbours<<<numQueries, MAX_PARENTS_PERQUERY >>> (m_objGPUInst.d_L2ParentIds,
												m_objGPUInst.d_L2ParentIds_aux,
												m_objGPUInst.d_FPSetCoordsList_Counts,
												m_objGPUInst.d_L2distances,
												m_objGPUInst.d_L2distances_aux,
												m_objGPUInst.d_nearestNeighbours,
												numQueries,
												m_objSearchParams.recall);


#ifdef _TIMERS
	gputimer.Stop();

	fp_set_time_gpu += gputimer.Elapsed() ;

	start = std::chrono::high_resolution_clock::now();
#endif
	gpuErrchk(cudaMemcpy(nearestNeighbours, m_objGPUInst.d_nearestNeighbours, sizeof(result_ann_t) * (m_objSearchParams.recall * numQueries),
				cudaMemcpyDeviceToHost));
	gpuErrchk(cudaMemcpy(nearestNeighbours_dist, m_objGPUInst.d_L2distances, sizeof(float) * (m_objSearchParams.recall * numQueries),
				cudaMemcpyDeviceToHost));

#ifdef _TIMERS
	stop = std::chrono::high_resolution_clock::now();
	time_transfer += std::chrono::duration_cast<std::chrono::nanoseconds>(stop-start).count() / 1000.0;
#endif
	// Re-rnking end
#ifdef _TIMERS
	auto milliEnd = log_message("SEARCH END");
#endif

#ifdef _TIMERS
	assert(time_B1_vec.size() >= 1);
	float time_B1_avg = time_B1_vec[0];
	time_B1 = time_B1_avg;
	for(unsigned idx=1; idx<time_B1_vec.size(); ++idx) {
		time_B1_avg = time_B1_avg + (time_B1_vec[idx] - time_B1_avg)/(idx+1); // running average
		time_B1 += time_B1_vec[idx];
	}

	assert(time_B2_vec.size() >= 1);
	float time_B2_avg = time_B2_vec[0];
	time_B2 = time_B2_avg;
	for(unsigned idx=1; idx<time_B2_vec.size(); ++idx) {
		time_B2_avg = time_B2_avg + (time_B2_vec[idx] - time_B2_avg)/(idx+1); // running average
		time_B2 += time_B2_vec[idx];
	}

	cout << "STATS:" << endl;
	cout << "Total Search iterations = " <<  iter << endl;
	cout << "(1) PD Dist Table Construction = " << time_K1 << " ms" << endl;
	//cout << "(2) avg. time_B1 = " << time_B1_avg << " ms" << endl;
	cout << "(2) Distance Computations = " << time_B1 << " ms" << endl;;
	//cout << "(4) avg. time_B2 = " << time_B2_avg << " ms" << endl;
	cout << "(3) Sort and Merge = " << time_B2 << " ms" << endl;
	cout << "(4) total neighbor_filtering_time = " << time_neighbor_filtering  << " ms" << endl;
	cout << "(5) Pre-fetch time = " << time_prfetch  << " ms" << endl;
	cout << "(6) Time elapsed in L2 Dist computation (GPU)= " << fp_set_time_gpu  << " ms" << endl;

	cout << "(7) total transfer_time (CPU <--> GPU) = " << time_transfer / 1000 << " ms" << endl;
	cout << "(8) total neigbbour seek time = " << seek_neighbours_time /  1000 << " ms" << endl;

	// Note : (5) not included, becasue it is shadowed by (8)
	double totalTime = time_K1 + time_B1 + time_neighbor_filtering + (time_transfer / 1000) +
					(seek_neighbours_time / 1000)  + time_prfetch  + fp_set_time_gpu; // in ms
	cout << "Total time from timers = (1) + (2) + (4) + (5) + (6) + (8) = " << totalTime << " ms" << endl;

	double totalTime_wallclock = milliEnd - milliStart;
	double throughput = (numQueries * 1000.0) / totalTime_wallclock;
	cout << "Wall Clock Time = " << totalTime_wallclock << endl;
	cout << "Throughput = " << throughput << " QPS" << endl;
	cout << "Throughput (Exclude Mem Transfers) = " << (numQueries * 1000.0) / (totalTime_wallclock - time_transfer / 1000) << " QPS" << endl;
#endif

#ifdef _DBG_CAND
	unsigned total_size=0;
	unsigned* FPSetCoordsList_Counts_temp = (unsigned*)malloc(sizeof(unsigned) * numQueries);

	gpuErrchk(cudaMemcpy(FPSetCoordsList_Counts_temp, m_objGPUInst.d_FPSetCoordsList_Counts, sizeof(unsigned) * numQueries, cudaMemcpyDeviceToHost ));
	for (int i=0; i< numQueries; i++)
	{
		total_size += FPSetCoordsList_Counts_temp[i];
	}
	free(FPSetCoordsList_Counts_temp);
	cout << "Total candidates " << total_size << endl;
#endif


}

// --------------- CUDA Kernels --------------- //

/**
 * This kernel computes the distances of all centroids from the query vectors, and populates the PQ Distance Tables for all queries
 * @param d_pqTable_T This is the PQ Table of dimension (D x 256), containing the co-ordinates of the centroids.
 *						Note: Size is D * 256 (and not chunks * 256 like PQ distances Matrix)
 * @param d_queriesFP This contains the full-precision coordinates of each of the queries.
 * @param d_pqDistTables This is the concatenated PQ Distance Tables of all the queries.
 * @param d_chunksOffset This stores the offset for indexing into the PQ_Table.
 * @param d_centroid This stores the coordinates of the centroid.
 * @param n_chunks This is the number of chunks in the compressed vector of a node.
 * @param beamWidth This is the beamwidth.
 */
template<typename T>
__global__ void populate_pqDist_par(float* d_pqTable_T,
									float* d_pqDistTables,
									T* d_queriesFP,
									unsigned* d_chunksOffset,
									float* d_centroid,
									unsigned n_chunks,
									unsigned long long D,
									unsigned n_DimAdjust)
 {
 	extern __shared__ char array[];
	T *query_vec = (T*)array;
	float *shm_centroid = (float*)( array + sizeof(T) * D)  ;
	unsigned queryID = blockIdx.x;
	unsigned pqDistTables_offset = queryID * 256 * n_chunks;	// Offset to the beginning of the pqTable entries for this query

	unsigned gid = queryID * (D - n_DimAdjust);
	unsigned tid = threadIdx.x;

	for(unsigned i= tid; i < D - (n_DimAdjust); i += blockDim.x) {
		query_vec[i] = d_queriesFP[gid + i];
		shm_centroid[i] = d_centroid[i];
	}

	if (tid >= D - (n_DimAdjust))
	{
		for(unsigned i= tid; i < D ; i += blockDim.x) {
			query_vec[i] = 0;
			shm_centroid[i] = d_centroid[i];
		}
	}

	__syncthreads();

	// Calculate and place 256 entries in the pqDistTables array corresponding to the each chunk
	for (unsigned chunk = 0; chunk < n_chunks; chunk++) {
		unsigned chunk_start = pqDistTables_offset + (256 * chunk);	// Size of pqDistTables = (numQueries * n_chunks * 256)
		for (unsigned j = d_chunksOffset[chunk]; j < d_chunksOffset[chunk + 1]; j++) { 	// if a chunk contains 4-dimensions
			const float *centers_dim_vec = d_pqTable_T + (256 * j);						// then j=0,1,2,3   4,5,6,7
			// ToDo should 256 be hard-coded or based on the dim?
			for (unsigned idx = tid; idx < 256; idx += blockDim.x) {					//// Memory Coalescing
				float diff = centers_dim_vec[idx] - ((T) query_vec[j] - shm_centroid[j]);

				d_pqDistTables[chunk_start + idx] += (float)(diff * diff);
			}
		}
	}
}

/** This kernel filters out those nodes from the neighborhood of nodes in "d_parents" that  have already been processed before (in a previous iteration) and populates d_neighbors with only the new unseen ones.
 * @param d_neighbors This is populated by the kernel to store the the node ids that will be considered in the next iteration, for each query.
 * @param d_neighbors_temp This stores the node ids of the neighborhood of the nodes fetched from host, for every query.
 * @param d_numNeighbors_query This is populated by the kernel to store the number of nodes in d_neighbors, for every query.
 * @param d_numNeighbors_query_temp This stores the number of neighbors fetched from the host, for every query.
 * @param d_processed_bit_vec This is a boolean vector for keeping track of whether a node is processed on not.
 * @param beamWidth This is the beamwidth.
 */
__global__ void neighbor_filtering_new (unsigned* d_neighbors,
										unsigned* d_neighbors_temp,
										unsigned* d_numNeighbors_query,
										unsigned* d_numNeighbors_query_temp,
										bool* d_processed_bit_vec,
										unsigned R) {
	unsigned queryID = blockIdx.x;
	unsigned tid = threadIdx.x;

	unsigned offset_neighbors = queryID * (R+1); //Offset into d_neighbors_temp array
	unsigned offset_bit_vec = queryID*BF_MEMORY;	//Offset into d_processed_bit_vec vector of bloom filter
	unsigned numNeighbors = d_numNeighbors_query_temp[queryID];
	bool* d_processed_bit_vec_start = d_processed_bit_vec + offset_bit_vec;

	// For each neighbor in d_neighbors_temp array check if its corresponding bits in the d_processed_bit_vec are already set
	for(unsigned ii=tid; ii < numNeighbors; ii += blockDim.x ) {
		unsigned nbr = d_neighbors_temp[offset_neighbors+ii];
		if(!((d_processed_bit_vec_start[hashFn1_d(nbr)]) && (d_processed_bit_vec_start[ hashFn2_d(nbr)])))
		{
			d_processed_bit_vec_start[ hashFn1_d(nbr)] = true;	//Set the bit to true
			d_processed_bit_vec_start[ hashFn2_d(nbr)] = true;	//Set the bit to true
			unsigned old = atomicAdd(&d_numNeighbors_query[queryID], 1);
			d_neighbors[offset_neighbors + old] = nbr;
		}
	}
}

/*Hash functions used for bloom filters */
__device__ unsigned hashFn1_d(unsigned x) {

	// FNV-1a hash
	uint64_t hash = 0xcbf29ce4;
	hash = (hash ^ (x & 0xff)) * 0x01000193 ;
	hash = (hash ^ ((x >> 8) & 0xff)) * 0x01000193;
	hash = (hash ^ ((x >> 16) & 0xff)) * 0x01000193;
	hash = (hash ^ ((x >> 24) & 0xff)) * 0x01000193;

	return hash % (BF_ENTRIES );
}

__device__ unsigned hashFn2_d(unsigned x) {

	// FNV-1a hash
	uint64_t hash = 0x84222325;
	hash = (hash ^ (x & 0xff)) * 0x1B3;
	hash = (hash ^ ((x >> 8) & 0xff)) * 0x1B3;
	hash = (hash ^ ((x >> 16) & 0xff)) * 0x1B3;
	hash = (hash ^ ((x >> 24) & 0xff)) * 0x1B3;
	return hash % (BF_ENTRIES);
}

/**
 * This kernel computes the Euclidean distances (using PQ Compressed Vectors) the neighbours with query point.
 * @param d_neighbors Array of neighbours whose dist to query vector has to be calculated
 * @param d_numNeighbors_query  Num of neighbours in the array.
 * @param d_compressedVectors PQ Compressed vectors to be used for distance calculation.
 * @param d_pqDistTables Pre-computed distance of the cluster centroids to Query Vector.
 * @param d_neighborsDist_query The computed distances in an Array.
 * @param n_chunks This is the number of chunks in the compressed vector of a node.
 * @param R This is the Degree of the Graph.
 */
__global__ void  compute_neighborDist_par(unsigned* d_neighbors,
											unsigned* d_numNeighbors_query,
											uint8_t* d_compressedVectors,
											float* d_pqDistTables,
											float*  d_neighborsDist_query,
											unsigned n_chunks,
											unsigned R) {


	unsigned tid = threadIdx.x;
	unsigned queryID = blockIdx.x;
	unsigned numNeighbors = d_numNeighbors_query[queryID];
	unsigned pqDistTables_offset = queryID * 256 * n_chunks;
	float* d_pqDistTables_start = d_pqDistTables + pqDistTables_offset;

	unsigned queryNeighbors_offset  = queryID * (R+1);	// offset into d_neighbors array
	unsigned* d_neighbors_start  = d_neighbors + queryNeighbors_offset;
	float* d_neighborsDist_query_start = d_neighborsDist_query + queryNeighbors_offset;
	uint8_t* d_compressedVectors_start = NULL;
	float sum = 0.0f;
	for(unsigned uIter = tid; uIter < numNeighbors; uIter += blockDim.x)
		d_neighborsDist_query_start[uIter] = 0;

	// The threadblock size is 8*R = 8*64 = 512. Each thread will compute dist on uChunks/8 dimensions
	#define THREADS_PER_NEIGHBOR 8
	typedef cub::WarpReduce<float,THREADS_PER_NEIGHBOR> WarpReduce;
	__shared__ typename WarpReduce::TempStorage temp_storage[MAX_R];

	for( unsigned j = tid/THREADS_PER_NEIGHBOR; j < numNeighbors; j += (blockDim.x)/THREADS_PER_NEIGHBOR ) { // assign eight threads to a neighbor, within a query


		d_compressedVectors_start = d_compressedVectors + ((unsigned long long)d_neighbors_start[j]) *n_chunks;
		sum = 0.0f;

		for(unsigned long long i = tid%THREADS_PER_NEIGHBOR; i < n_chunks; i += THREADS_PER_NEIGHBOR ){
			sum += d_pqDistTables_start[(i * 256) + d_compressedVectors_start[i]];
		}

		d_neighborsDist_query_start[j] = WarpReduce(temp_storage[j]).Sum(sum);
	}
}

/**
 * This kernel computes the Euclidean distances of the candidates (parents)  with query point.
 * @param d_FPSetCoordsList 2D Array of FP Vectors corresponding to the candidates for all queries.
 * @param d_FPSetCoordsList_Counts  No of entries in each column (query) i.e. No of candidates for each query
 * @param d_queriesFP Array of input queries
 * @param d_L2ParentIds 2D Array with the entries of Parent IDs/ Candidates.
 * @param d_L2distances The calculated Distances for each of the parents.
 * @param d_numQueries Number of Queries.
 * @param D No of Dimension in Dataset (for mips, the inflated dimension).
 * @param n_DimAdjust Number of dummy dimensions i.e. Zero-value dimensions appended for MIPS to L2 conversion.
 */
template<typename T>
__global__ void compute_L2Dist (T* d_FPSetCoordsList,
								unsigned* d_FPSetCoordsList_Counts,
								T* d_queriesFP,
								unsigned* d_L2ParentIds,
								float* d_L2distances,
								unsigned d_numQueries,
								unsigned long long D,
								unsigned n_DimAdjust)
{
	extern __shared__ char array[];

	T* query_vec = (T*) array;
	unsigned queryID = blockIdx.x;
	unsigned numNodes = d_FPSetCoordsList_Counts[queryID];
	unsigned tid = threadIdx.x;
	unsigned gid =  queryID * (D - n_DimAdjust);

	// ToDo : see if this can be re-used from global, instead of re-defining here
	const unsigned long long FPSetCoords_size = D;
	const unsigned long long FPSetCoords_rowsize = FPSetCoords_size * d_numQueries;

	for(unsigned ii= tid; ii < D - (n_DimAdjust); ii += blockDim.x) {
		query_vec[ii] = d_queriesFP[gid + ii];
	}

	if (tid >= D - (n_DimAdjust))
	{
		for(unsigned i= tid; i < D ; i += blockDim.x) {
			query_vec[i] = 0;

		}
	}

	__syncthreads();

	// one thread block computes the distances of all the nodes for a query,
	for(unsigned ii = tid; ii < numNodes; ii += blockDim.x) {
		float L2Dist = 0.0;
		for(unsigned jj=0; jj < D; ++jj) {
			float diff = d_FPSetCoordsList[(FPSetCoords_rowsize * ii) + (queryID * FPSetCoords_size) + jj] - query_vec[jj];
			L2Dist = L2Dist + (diff * diff);
		}
		d_L2distances[( d_numQueries * ii) + queryID ] = L2Dist;
	}
}

/**
 * This kernel picks the topk nearest neighbours from the list of parents/candidates based on thier L2 distances.
 * @param d_L2ParentIds 2D Array with the entries of Parent IDs/ Candidates.
 * @param d_L2ParentIds_aux Temporary 2D Array with the entries of Parent IDs/ Candidates.
 * @param d_FPSetCoordsList_Counts  No of entries in each column (query) i.e. No of candidates for each query
 * @param d_L2distances 2D Array with calculated Distances for each of the parents.
 * @param d_L2distances_aux Temporary 2D Array with calculated Distances for each of the parents..
 * @param d_nearestNeighbours[OUT] Array of final ANN. ANNs of Query1, ANNs of query2 etc.
 * @param d_numQueries Number of Queries.
 * @param d_recall The recall value specified by user
*/
__global__ void  compute_NearestNeighbours(unsigned* d_L2ParentIds,
						unsigned* d_L2ParentIds_aux,
						unsigned* d_FPSetCoordsList_Counts,
						float* d_L2distances,
						float* d_L2distances_aux,
						result_ann_t* d_nearestNeighbours,
						unsigned d_numQueries,
						unsigned d_recall)
{
    unsigned tid = threadIdx.x;
    unsigned queryID = blockIdx.x;
    unsigned numNeighbors = d_FPSetCoordsList_Counts[queryID];

    if(tid >= numNeighbors || numNeighbors <= 0) return;

    __shared__ unsigned shm_pos[MAX_PARENTS_PERQUERY + 1];

	// perform parallel merge sort
	for(unsigned subArraySize=2; subArraySize< 2*numNeighbors; subArraySize *= 2){
		unsigned subArrayID = tid/subArraySize;
		unsigned start = subArrayID * subArraySize;
		unsigned mid = min(start + subArraySize/2, numNeighbors);
		unsigned end = min(start + subArraySize, numNeighbors);

		if(tid >= start && tid < mid){
			unsigned lowerBound = lower_bound_d_ex(&d_L2distances[mid * (d_numQueries)], 0, end-mid, d_L2distances[(tid * (d_numQueries)) + queryID],
								d_numQueries, queryID);
			shm_pos[tid] = lowerBound + tid;	// Position for this element
		}

		if(tid >= mid && tid < end)  {
			unsigned upperBound = upper_bound_d_ex(&d_L2distances[start * (d_numQueries)], 0, mid-start, d_L2distances[(tid * (d_numQueries)) + queryID],
								d_numQueries, queryID);
			shm_pos[tid] = start + (upperBound + tid-mid);	// Position for this element

		}
		__syncthreads();
		__threadfence_block();

		// Copy the neighbors to auxiliary array at their correct position
		for(int i=tid; i < numNeighbors; i += blockDim.x) {
			d_L2distances_aux[(shm_pos[i]* (d_numQueries)) + queryID] = d_L2distances[(i * (d_numQueries)) + queryID];
			d_L2ParentIds_aux[(shm_pos[i]* (d_numQueries)) + queryID] = d_L2ParentIds[(i * (d_numQueries)) + queryID];
		}
		__syncthreads();
		// Copy the auxiliary array to original array
		for(int i=tid; i < numNeighbors; i += blockDim.x) {
			d_L2distances[(i * (d_numQueries)) + queryID] = d_L2distances_aux[(i * (d_numQueries)) + queryID];
			d_L2ParentIds[(i * (d_numQueries)) + queryID] = d_L2ParentIds_aux[(i * (d_numQueries)) + queryID];
		}
		__syncthreads();
	}
	for(unsigned ii = tid; ii < d_recall; ii += blockDim.x)
	{
		d_nearestNeighbours[( (d_recall * queryID) ) + ii ] = d_L2ParentIds[( (d_numQueries) * ii) + queryID ];
	}
}

/** This kernel populates the list of nodes whose neighborhood information has to be fetched in the next iteration.
 *  The closet neighbour from Best_L_Set and  neighbors' list is quickly fetched (pre-fetch) before the complete update of worklist happens with the neighbour list happens
 * @param d_neighbors This is the concatenated list of node ids for all queries whose distances have to be computed with the respective queries.
 * @param d_numNeighbors_query This stores for every query the number of nodes in d_neighbors.
 * @param d_neighborsDist_query This contains the distances between the node ids in d_neighbors and the respective query for all queries.
 * @param d_BestLSets This contains the concatenated list of the candidate sets for all queries.
 * @param d_BestLSetsDist contains the contatenated list of the distances of the candidate nodes to the respective query, for all queries.
 * @param d_BestLSets_visited This maintains the boolean information about if an entry in the d_BestLSets has been processed or not.
 * @param d_parents This is populated with the list of nodes whose neighborhood information has to be fetched in the next iteration of the outer while loop, for all queries.
 * @param beamWidth This is the beamwidth.
 * @param d_nextIter This maintains boolean flags for all queries, to decide if a query is to processed in the next iteration.
 * @param d_BestLSets_count contains the number of nodes in the d_BestLSets, for every query.
 * @param d_mark Stores the node ID to be marked visited in Best_L_Set in the next invocation of compute_BestLSets_par_merge kernel
 */
 __global__ void  compute_parent2(unsigned* d_neighbors, unsigned* d_numNeighbors_query, float* d_neighborsDist_query,
 								unsigned* d_BestLSets, float* d_BestLSetsDist, bool* d_BestLSets_visited,
 								unsigned* d_parents, bool* d_nextIter, unsigned* d_BestLSets_count,
 								unsigned* d_mark,
 								unsigned* d_iter,
 								unsigned* d_L2ParentIds,
 								unsigned* d_FPSetCoordsList_Counts,
 								unsigned d_numQueries,
								unsigned uWLLen,
								unsigned long long MEDOID,
								unsigned R)
 {
	unsigned tid = threadIdx.x;
  	unsigned queryID = (blockIdx.x*blockDim.x) + tid;
	if (queryID >= (d_numQueries) )
		return;

  	// Single thread is enough to compute the parent (pre-fetched) for a query. So, One ThreadBlock can work
  	// on computing parents for blockDim.x Queries
	unsigned numNeighbors = d_numNeighbors_query[queryID];
	unsigned Best_L_Set_size = d_BestLSets_count[queryID];

	float dist=3.402823E+38;	//assigning max float value
	unsigned index = 0;

	unsigned offset = queryID*(R+1);

	/*Locate closest neighbor in neighbor list*/
	//  Note: MEDOID is excluded becasue we already fetched its children in the very beginning
	for(unsigned ii=0; ii < numNeighbors; ++ii) {
		if(d_neighborsDist_query[offset + ii] < dist && d_neighbors[offset+ii]!= MEDOID){
			index=offset+ii;
			dist=d_neighborsDist_query[index];
		}
	}
	unsigned parentOffset = queryID*(SIZEPARENTLIST);
	unsigned parentIndex = 0;
	unsigned LOffset = uWLLen*queryID;
	unsigned LIndex = LOffset;

	/*Compare closest neighbor in neighbor list with first unvisited node in Best_L_Set*/
	for(unsigned ii=0; ii < Best_L_Set_size; ++ii) {
		LIndex = LOffset + ii;
		if(!d_BestLSets_visited[LIndex]){
			parentIndex++;
			if(dist<d_BestLSetsDist[LIndex]){
				d_parents[parentOffset + parentIndex] = d_neighbors[index];
				d_mark[queryID]= d_neighbors[index];
			}
			else{
				d_parents[parentOffset + parentIndex] = d_BestLSets[LIndex];
				d_BestLSets_visited[LIndex] = true;
			}
			break;
		}
	}

	/*Corner case*/
	if(parentIndex==0 && dist<d_BestLSetsDist[LOffset+Best_L_Set_size-1]){
		parentIndex++;
		d_parents[parentOffset + parentIndex] = d_neighbors[index];
		d_mark[queryID]= d_neighbors[index];
	}

	// For every query, indicates whether a next parent if found or not
	d_parents[parentOffset] = parentIndex;

	if(parentIndex != 0) // parentIndex == 0 is the termination condition for the algorithm.
	{
		*d_nextIter = true;
		// Note: One thread assigned to one Query, so ok to increment (no contention)
		d_FPSetCoordsList_Counts[queryID]++;
		// At this point the count of parent is one ahead of the iteration number
		d_L2ParentIds[( (*d_iter) * d_numQueries) + queryID] = d_parents[parentOffset + parentIndex];
	}
 }

// This is just a copy of the compute_parent2 kernel with some optimizations for the initial case i.e. when serach iterations have not started.
// The very first time we are computing the parent and work list is not yet initialized. So, we can just pick the closet
// neighbour from the list of neighbours directly w/o considering the worklist entries (empty).
 __global__ void  compute_parent1(unsigned* d_neighbors, unsigned* d_numNeighbors_query, float* d_neighborsDist_query,
 								unsigned* d_BestLSets, float* d_BestLSetsDist, bool* d_BestLSets_visited,
 								unsigned* d_parents, bool* d_nextIter, unsigned* d_BestLSets_count,
 								unsigned* d_mark,
 								unsigned* d_iter,
 								unsigned* d_L2ParentIds,
 								unsigned* d_FPSetCoordsList_Counts,
 								unsigned d_numQueries,
								unsigned long long MEDOID,
								unsigned R)
 {
	unsigned tid = threadIdx.x;
  	unsigned queryID = (blockIdx.x*blockDim.x) + tid;
	if (queryID >= d_numQueries )
		return;

  	// Single thread is enough to compute the parent (pre-fetched) for a query. So, One ThreadBlock can work
  	// on computing parents for blockDim.x Queries
	unsigned numNeighbors = d_numNeighbors_query[queryID];

	float dist=3.402823E+38;	//assigning max float value
	unsigned index = 0;

	unsigned offset = queryID *(R+1);

	/*Locate closest neighbor in neighbor list*/
	//  Note: MEDOID is excluded becasue we already fetched its children in the very beginning
	for(unsigned ii=0; ii < numNeighbors; ++ii) {
		if(d_neighborsDist_query[offset + ii] < dist && d_neighbors[offset+ii]!= MEDOID){
			index=offset+ii;
			dist=d_neighborsDist_query[index];
		}
	}

	unsigned parentIndex = 0;

//	if(Best_L_Set_size==0){ // this is the case as worklist size == 0 before search iterations start
		parentIndex++;
		d_parents[queryID*(SIZEPARENTLIST)+parentIndex] = d_neighbors[index];
		d_mark[queryID]= d_neighbors[index];
		// Lets mark this nodeID for re-ranking later
		//d_basepoints_parentqueries[d_neighbors[index]] = queryID;
//	}

	// Place the parent in d_parents array if parent is decided and set the next iteration flag to true
	// indicates the numParents used in neighbours seeking step
	d_parents[queryID*(SIZEPARENTLIST)] = parentIndex;
	// Note: parentIndex should ideally be accessed in a synchronized manner.
	// (but only WRITEs (no READs) are there now,   so its ok)
//	if(parentIndex != 0) // parentIndex == 0 is the termination condition for the algorithm.
	{
		*d_nextIter = true;
		// Note: One thread assigned to one Query, so ok to increment (no contention)
		d_FPSetCoordsList_Counts[queryID]++;
		d_L2ParentIds[( (*d_iter) * d_numQueries) + queryID] = d_parents[queryID*(SIZEPARENTLIST)+parentIndex];
	}

}

/** This kernel sorts the neighbors (for every query) in increasing order of their distances to the query, using parallel merge sort
 * The sorted list of neighbors is stored in "d_neighbors" at the end of the kernel.
 * @param d_neighbors This is the concatenated list of node ids for all queries whose distances have to be computed with the respective queries.
 * @param d_neighbors_aux This is an auxiliary array for d_neighbors, used for merge sort.
 * @param d_numNeighbors_query This stores for every query the number of nodes in d_neighbors.
 * @param d_neighborsDist_query This contains the distances between the node ids in d_neighbors and the respective query for all queries.
 * @param d_neighborsDist_query_aux This is an auxiliary array for d_neighborsDist_query, used for merge sort.
 * @param d_nextIter This maintains boolean flags for all queries, to decide if a query is to processed in the next iteration.
 * @param R Graph degree.
 */
__global__ void  compute_BestLSets_par_sort_msort(unsigned* d_neighbors,
													unsigned* d_neighbors_aux,
													unsigned* d_numNeighbors_query,
													float* d_neighborsDist_query,
													float* d_neighborsDist_query_aux,
													bool* d_nextIter,
													unsigned R) {


	unsigned tid = threadIdx.x;
    unsigned queryID = blockIdx.x;
    unsigned numNeighbors = d_numNeighbors_query[queryID];
    *d_nextIter = false;

    if(tid >= numNeighbors || numNeighbors <= 0) return;

    __shared__ unsigned shm_pos[MAX_R+1];
    unsigned offset = queryID*(MAX_R+1);	// Offset into d_neighborsDist_query, d_neighborsDist_query_aux, d_neighbors_aux and d_neighbors arrays

	// perform parallel merge sort
	for(unsigned subArraySize=2; subArraySize< 2*numNeighbors; subArraySize *= 2){
		unsigned subArrayID = tid/subArraySize;
		unsigned start = subArrayID * subArraySize;
		unsigned mid = min(start + subArraySize/2, numNeighbors);
		unsigned end = min(start + subArraySize, numNeighbors);

		if(tid >= start && tid < mid){
			unsigned lowerBound = lower_bound_d(&d_neighborsDist_query[offset + mid], 0, end-mid, d_neighborsDist_query[offset + tid]);
			shm_pos[tid] = lowerBound + tid;	// Position for this element
		}

		if(tid >= mid && tid < end)  {
			unsigned upperBound = upper_bound_d(&d_neighborsDist_query[offset + start], 0, mid-start, d_neighborsDist_query[offset + tid]);
			shm_pos[tid] = start + (upperBound + tid-mid);	// Position for this element

		}
		__syncthreads();
		__threadfence_block();

		// Copy the neighbors to auxiliary array at their correct position
		for(int i=tid; i < numNeighbors; i += blockDim.x) {
			d_neighborsDist_query_aux[offset + shm_pos[i]] = d_neighborsDist_query[offset+i];
			d_neighbors_aux[offset + shm_pos[i]] = d_neighbors[offset+i];
		}
		__syncthreads();
		// Copy the auxiliary array to original array
		for(int i=tid; i < numNeighbors; i += blockDim.x) {
			d_neighborsDist_query[offset + i] = d_neighborsDist_query_aux[offset+i];
			d_neighbors[offset + i] = d_neighbors_aux[offset+i];
		}
		__syncthreads();
	}
}

/** This kernel merges the current Best_L_Set (candidate set) with the list of sorted neighbors (in d_neighbors) to update the candidate
  set.
 * @param d_neighbors This is the concatenated list of node ids for all queries whose distances have to be computed with the respective queries.
 * @param d_numNeighbors_query This stores for every query the number of nodes in d_neighbors.
 * @param d_neighborsDist_query This contains the distances between the node ids in d_neighbors and the respective query for all queries.
 * @param d_BestLSets[OUT] This contains the concatenated list of the candidate sets for all queries.
 * @param d_BestLSetsDist[OUT] contains the contatenated list of the distances of the candidate nodes to the respective query, for all queries.
 * @param d_BestLSets_visited[OUT] This maintains the boolean information about if an entry in the d_BestLSets has been processed or not.
 * @param d_parents This is populated with the list of nodes whose neighborhood information has to be fetched in the next iteration of the outer while loop, for all queries.
 * @param iter Search iteration number
 * @param d_nextIter This maintains boolean flags for all queries, to decide if a query is to processed in the next iteration.
 * @param d_BestLSets_count contains the number of nodes in the d_BestLSets, for every query.
 * @param d_mark Stores the node ID to be marked visited in Best_L_Set in the next invocation of compute_BestLSets_par_merge kernel
 * @param uWLLen Worklist Length
 * @param MEDOID Medoid of the Graph.
 * @param R Graph degree.
 *
 */
__global__ void  compute_BestLSets_par_merge(unsigned* d_neighbors,
											unsigned* d_numNeighbors_query,
											float* d_neighborsDist_query,
											unsigned* d_BestLSets,
											float* d_BestLSetsDist,
											bool* d_BestLSets_visited,
											unsigned* d_parents,
											unsigned iter,
											bool* d_nextIter,
											unsigned* d_BestLSets_count,
											unsigned* d_mark,
											unsigned uWLLen,
											unsigned long long MEDOID,
											unsigned R){
	extern __shared__ char array[];
	float *shm_neighborsDist_query = (float*) array; // R+1 is an upperbound on the number of neighbors
	__shared__ float shm_currBestLSetsDist[MAX_L];
	__shared__ float shm_BestLSetsDist[MAX_L];
	__shared__ unsigned shm_pos[MAX_R+MAX_L+1];
	__shared__ unsigned shm_BestLSets[MAX_L];
	__shared__ bool shm_BestLSets_visited[MAX_L];

	unsigned queryID = blockIdx.x;
	unsigned numNeighbors = d_numNeighbors_query[queryID];
	unsigned tid = threadIdx.x;

	unsigned Best_L_Set_size  = 0;
	unsigned newBest_L_Set_size = d_BestLSets_count[queryID];
	unsigned nbrsBound;
	unsigned offset = queryID*(R+1);

	if(numNeighbors > 0){	// If the number of neighbors after filteration is zero then makes no sense to do merging

        if(iter==1){	// If this is the first call to compute_BestLSets_par_merge by this query then initialize d_BestLSets, d_BestLSetsDist...
                nbrsBound = min(numNeighbors,uWLLen);
                for(unsigned ii=tid; ii < nbrsBound; ii += blockDim.x) {
                        unsigned nbr =  d_neighbors[offset + ii];
                        d_BestLSets[queryID*uWLLen + tid] = nbr;
                        d_BestLSetsDist[queryID*uWLLen + tid] =   d_neighborsDist_query[offset + ii];
                        d_BestLSets_visited[queryID*uWLLen + tid] = ( nbr == MEDOID);
                }
                __syncthreads();
                newBest_L_Set_size = nbrsBound;
                d_BestLSets_count[queryID] = nbrsBound;
        }
        else {
                Best_L_Set_size = d_BestLSets_count[queryID];
                float maxBestLSetDist = d_BestLSetsDist[uWLLen*queryID+Best_L_Set_size-1];
                for(nbrsBound = 0; nbrsBound < min(uWLLen,numNeighbors); ++nbrsBound) {
                        if(d_neighborsDist_query[offset + nbrsBound] >= maxBestLSetDist){
                                break;
                        }
                }


                nbrsBound = max(nbrsBound, min(uWLLen-Best_L_Set_size, numNeighbors));
                // if both Best_L_Set_size and numNeighbors is less than L, then the max of the two will be the newBest_L_Set_size otherwise it will be L
                newBest_L_Set_size = min(Best_L_Set_size + nbrsBound, uWLLen);

                d_BestLSets_count[queryID] = newBest_L_Set_size;


				/*perform parallel merge */
                for(int i=tid; i < nbrsBound; i += blockDim.x) {
                        shm_neighborsDist_query[i] = d_neighborsDist_query[offset + i];
                }
                for(int i=tid; i < Best_L_Set_size; i += blockDim.x) {
                        shm_currBestLSetsDist[i] = d_BestLSetsDist[uWLLen*queryID+i];
                }
                __syncthreads();
                if(tid < nbrsBound) {
                        shm_pos[tid] =  lower_bound_d(shm_currBestLSetsDist, 0, Best_L_Set_size, shm_neighborsDist_query[tid]) + tid;
                }
                if( tid >= nbrsBound && tid < (nbrsBound + Best_L_Set_size)) {
                        shm_pos[tid] =  upper_bound_d(shm_neighborsDist_query, 0, nbrsBound, shm_currBestLSetsDist[tid-nbrsBound]) + (tid-nbrsBound);
                }

                __syncthreads();
                __threadfence_block();

                // all threads of the block have populated the positions array in shared memory
                if(tid < nbrsBound && shm_pos[tid] < newBest_L_Set_size)  {
                        shm_BestLSetsDist[shm_pos[tid]] = shm_neighborsDist_query[tid];
                        shm_BestLSets[shm_pos[tid]] = d_neighbors[offset+tid];
                        shm_BestLSets_visited[shm_pos[tid]] = false;
                }
                if(tid >= nbrsBound && tid < (nbrsBound + Best_L_Set_size) && shm_pos[tid] < newBest_L_Set_size) {
                        shm_BestLSetsDist[shm_pos[tid]] = shm_currBestLSetsDist[tid-nbrsBound];
                        shm_BestLSets[shm_pos[tid]] = d_BestLSets[queryID*uWLLen+(tid-nbrsBound)];
                        shm_BestLSets_visited[shm_pos[tid]] = d_BestLSets_visited[queryID*uWLLen+(tid-nbrsBound)];
                }

                __syncthreads();
                __threadfence_block();

                //Copying back from shared memory to device array
                if (tid < newBest_L_Set_size) {
                        d_BestLSetsDist[uWLLen*queryID+tid] = shm_BestLSetsDist[tid];
                        d_BestLSets[uWLLen*queryID+tid] = shm_BestLSets[tid];
                        d_BestLSets_visited[uWLLen*queryID+tid] = shm_BestLSets_visited[tid];
                    }
                __syncthreads();
                __threadfence_block();
        }
	}
		// Mark the node extracted by compute_parent kernel as visited
        for(int i=tid;i<newBest_L_Set_size;i=i+blockDim.x){
                if(d_mark[queryID]==d_BestLSets[uWLLen*queryID+tid])
                        d_BestLSets_visited[uWLLen*queryID+tid]=true;
        }
}

/*Helper device function which returns the position first element in the range [lo,hi), which has a value not less than 'target'.*/
__device__ unsigned lower_bound_d(float arr[], unsigned lo, unsigned hi, float target) {
	unsigned mid;

	while(lo < hi) {
		mid = (lo + hi)/2;
		float val = arr[mid];
		if (target <= val)
			hi = mid;
		else
			lo = mid + 1;
	}

	return lo;

}

/*Helper device function which returns the position first element in the range (lo,hi], which has a value greater than 'target'.*/
__device__ unsigned upper_bound_d(float arr[], unsigned lo, unsigned hi, float target) {

	unsigned mid;

	while(lo < hi) {
		mid = (lo + hi)/2;
		float val = arr[mid];
		if (target >= val)
			lo = mid+1;
		else
			hi = mid;
	}

	return lo;
}

/*Helper device function which returns the position first element in the range [lo,hi), which has a value not less than 'target'.*/
__device__ unsigned lower_bound_d_ex(float arr[], unsigned lo, unsigned hi, float target, unsigned row_size, unsigned queryID)
{
	unsigned mid;

	while(lo < hi) {
		mid = (lo + hi)/2;
		float val = arr[(mid*row_size) + queryID];
		if (target <= val)
			hi = mid;
		else
			lo = mid + 1;
	}

	return lo;

}

/*Helper device function which returns the position first element in the range (lo,hi], which has a value greater than 'target'.*/
__device__ unsigned upper_bound_d_ex(float arr[], unsigned lo, unsigned hi, float target,  unsigned row_size, unsigned queryID)
{

	unsigned mid;

	while(lo < hi) {
		mid = (lo + hi)/2;
		float val = arr[(mid*row_size) + queryID];
		if (target >= val)
			lo = mid+1;
		else
			hi = mid;
	}

	return lo;
}

#if 0
void bang_set_searchparams_c(int recall, int worklist_length, DistFunc nDistFunc)
{
	m_objSearchParams.recall = recall;
	m_objSearchParams.worklist_length = worklist_length;
	m_objSearchParams.uDistFunc = nDistFunc;
	assert(m_objSearchParams.worklist_length <= MAX_L);	// Max thread block size
}
void bang_load_c(char* pszPath)
{
	// ToDo: Add other datatypes
	bang_load<uint8_t>(pszPath);
}

void bang_query_c(uint8_t* query_array, int num_queries,
					result_ann_t* nearestNeighbours,
					float* nearestNeighbours_dist )
{
	bang_query<uint8_t>(query_array,num_queries, nearestNeighbours, nearestNeighbours_dist );
}
#endif